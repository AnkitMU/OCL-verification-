# OCL Normalization Usage in the Framework

## Overview

OCL Normalization is applied **selectively** in the hybrid OCL pattern classification framework. It transforms logically equivalent but syntactically different OCL expressions into canonical forms to improve pattern recognition.

## When Normalization IS Applied

### 1. ‚úÖ Pattern Validation Framework (`pattern_validation.py`)

**Location**: `src/ssr_ocl/validation/pattern_validation.py`

```python
class PatternValidator:
    def __init__(self):
        self.normalizer = OCLNormalizer(enable_logging=False)
    
    def validate_example(self, example: ValidationExample):
        # Applies normalization if example.should_normalize = True
        if example.should_normalize:
            normalized = self.normalizer.normalize(example.constraint)
            pattern = self.detector.detect_pattern(normalized)
```

**Use Case**: 
- Ground truth validation of 50 pattern types
- Testing that normalization improves classification accuracy
- Regression testing

**Example**:
```ocl
# Before normalization
self.items->isEmpty() or self.items->forAll(i | i.valid)

# After normalization
self.items->notEmpty() implies self.items->forAll(i | i.valid)

# Result: Correctly classified as 'boolean_guard_implies'
```

### 2. ‚úÖ Regression Tests (`test_pattern_regression.py`)

**Location**: `tests/test_pattern_regression.py`

```python
def test_normalization_improves_classification(validator):
    constraint = "self.items->isEmpty() or self.items->forAll(i | i.valid)"
    
    # With normalization
    normalized = validator.normalizer.normalize(constraint)
    pattern = validator.detector.detect_pattern(normalized)
    
    assert pattern.value in ['boolean_guard_implies', 'contractual_temporal']
```

**Use Case**: Automated tests to ensure normalization continues working correctly

---

## When Normalization IS NOT Applied

### 1. ‚ùå Enhanced Framework Test (`test_enhanced_framework.py`)

**Location**: `src/ssr_ocl/super_encoder/test_enhanced_framework.py`

**Pattern Detection Phase (Phase 3)**:
```python
def test_phase_3_pattern_detection(self):
    for constraint in constraints:
        # NO NORMALIZATION APPLIED
        if self.use_neural_classifier:
            pattern_name, confidence = self.classifier.predict(constraint['text'])
        else:
            pattern = self.detector.detect_pattern(constraint['text'])
```

**Why**: The comprehensive regex detector (`ComprehensivePatternDetector`) has 611 patterns that handle many syntactic variations WITHOUT needing normalization.

### 2. ‚ùå Comprehensive Pattern Detector (`comprehensive_pattern_detector.py`)

**Location**: `src/ssr_ocl/super_encoder/comprehensive_pattern_detector.py`

```python
class ComprehensivePatternDetector:
    def detect_pattern(self, constraint_text: str):
        # Direct regex matching - NO normalization step
        for compiled_regex, pattern_type in self.compiled_patterns:
            if compiled_regex.search(constraint_text):
                return pattern_type
```

**Why**: The 611 regex patterns are comprehensive enough to match common variations directly.

### 3. ‚ùå Neural Classifier (`classifier.py`)

**Location**: `src/ssr_ocl/classifiers/sentence_transformer/classifier.py`

```python
def predict(self, ocl_text: str):
    # NO normalization applied
    embedding = self.model.encode([ocl_text])
    prediction = self.classifier.predict(embedding)
```

**Why**: Neural models learn semantic patterns and can recognize equivalent expressions without explicit normalization.

---

## Normalization Rules (20+ transformations)

### Guarded Implication Patterns
```ocl
X->isEmpty() or P          ‚Üí  X->notEmpty() implies P
X = null or P              ‚Üí  X <> null implies P  
X->size() = 0 or P         ‚Üí  X->notEmpty() implies P
```

### Boolean Logic Simplification
```ocl
not (A and B)              ‚Üí  not A or not B        (De Morgan)
not (A or B)               ‚Üí  not A and not B       (De Morgan)
not not P                  ‚Üí  P                      (Double negation)
```

### Collection Properties
```ocl
not X->isEmpty()           ‚Üí  X->notEmpty()
X->size() > 0              ‚Üí  X->notEmpty()
X->size() >= 1             ‚Üí  X->notEmpty()
```

### Comparison Normalization
```ocl
not (X = Y)                ‚Üí  X <> Y
not (X <> Y)               ‚Üí  X = Y
```

---

## Current Test Results (Phase 3: Pattern Detection)

From `test_enhanced_framework.py` output:

```
üéØ Detecting patterns in 23 constraints:

 1. University_DepartmentsNonEmpty ‚Üí size_constraint (conf: 0.997)
 2. University_ProfessorEmailsUnique ‚Üí uniqueness_constraint (conf: 0.998)
 3. University_StudentIdsUnique ‚Üí uniqueness_constraint (conf: 1.000)
 ...
23. Building_RoomsNonEmpty ‚Üí size_constraint (conf: 0.909)

üìã Neural Classifier Stats:
   Average Confidence: 0.696
   High Confidence (>=0.5): 19/23
   Regex Fallback Used: 4/23 (17%)
```

**Key Insight**: 83% of constraints classified by neural network **WITHOUT normalization**, 17% using comprehensive regex detector with 611 patterns.

---

## Should Normalization Be Added to the Main Pipeline?

### ‚úÖ Pros:
1. Could improve classification for edge cases
2. Reduces burden on regex pattern count (currently 611 patterns)
3. Makes patterns more semantically consistent

### ‚ùå Cons:
1. Current accuracy already high (95.7% validation, 69.6% neural confidence)
2. Comprehensive regex detector handles variations well
3. Neural classifier learns semantic patterns naturally
4. Performance overhead (text transformation step)

### üéØ Recommendation:
**Keep normalization in validation/testing only** - The current hybrid approach (neural 83% + regex 17%) achieves excellent results without normalization in the main pipeline. Add normalization only if:
- Validation accuracy drops below 90%
- Specific pattern types consistently misclassified
- User reports classification issues on production data

---

## How to Enable Normalization in Main Pipeline

If you want to add normalization to Phase 3 (Pattern Detection):

```python
# In test_enhanced_framework.py, Phase 3:
from ssr_ocl.super_encoder.ocl_normalizer import OCLNormalizer

def test_phase_3_pattern_detection(self):
    normalizer = OCLNormalizer(enable_logging=True)  # Add this
    
    for constraint in constraints:
        # Apply normalization before classification
        normalized_text = normalizer.normalize(constraint['text'])
        
        if self.use_neural_classifier:
            pattern_name, confidence = self.classifier.predict(normalized_text)
        else:
            pattern = self.detector.detect_pattern(normalized_text)
```

---

## Summary

| **Component** | **Normalization Applied?** | **Reason** |
|---------------|---------------------------|-----------|
| Pattern Validation | ‚úÖ YES | Testing normalization effectiveness |
| Regression Tests | ‚úÖ YES | Ensuring normalization correctness |
| Enhanced Framework (Phase 3) | ‚ùå NO | 611 regex patterns + neural are sufficient |
| Comprehensive Detector | ‚ùå NO | Direct regex matching with 611 patterns |
| Neural Classifier | ‚ùå NO | Learns semantic patterns naturally |
| SMT Encoder | ‚ùå NO | Works with original constraint text |

**Bottom Line**: Normalization is a **validation tool** to ensure the system handles equivalent expressions correctly, but is **not required in production** due to the comprehensive regex detector (611 patterns) and neural classifier achieving 95.7% validation accuracy without it.
